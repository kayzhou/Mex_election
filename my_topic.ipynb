{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_weapon import *\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "nlp = spacy.load('es', disable=['parser', 'ner'])\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def normalize_lower(text):\n",
    "    return unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = json.load(open(\"data/spanish-stop-words.json\"))[\"words\"]\n",
    "stop_words = [normalize_lower(w) for w in stop_words]\n",
    "stop_words.extend([\n",
    "    \"rt\", \"…\", \"...\", \"URL\", \"http\", \"https\", \"“\", \"”\", \"‘\", \"’\", \"get\", \"2\", \"new\", \"one\", \"i'm\", \"make\",\n",
    "    \"go\", \"good\", \"say\", \"says\", \"know\", \"day\", \"..\", \"take\", \"got\", \"1\", \"going\", \"4\", \"3\", \"two\", \"n\",\n",
    "    \"like\", \"via\", \"u\", \"would\", \"still\", \"first\", \"that's\", \"look\", \"way\", \"last\", \"said\", \"let\",\n",
    "    \"twitter\", \"ever\", \"always\", \"another\", \"many\", \"things\", \"may\", \"big\", \"come\", \"keep\", \"RT\",\n",
    "    \"5\", \"time\", \"much\", \"_\", \"cound\", \"-\", '\"'\n",
    "])\n",
    "stop_words.extend([',', '.', ':', ';', '?', '(', ')', '[', ']', '&', '!', '*', '@', '#', '$', '%', '|'])\n",
    "stop_words = set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ec3f790bfd4f16a88a8c9792b6f355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "texts_out = []    \n",
    "for line in tqdm(open(\"data/LDA_corpus.txt\")):\n",
    "    ## words = [w for w in line.strip().split() if w not in stop_words and len(w) > 1]\n",
    "    words = [w for w in line.strip().split() if w not in stop_words and len(w) > 1]\n",
    "    texts_out.append(words)\n",
    "\n",
    "#         # Create Dictionary\n",
    "#         self.id2word = corpora.Dictionary(texts_out)\n",
    "\n",
    "#         # Create Corpus\n",
    "#         self.texts = texts_out\n",
    "\n",
    "#         # Term Document Frequency\n",
    "#         self.corpus = [self.id2word.doc2bow(text) for text in texts_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "# nlp = spacy.load('en')\n",
    "import re\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV', 'PROPN']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    i = 0\n",
    "    for sent in tqdm(texts):\n",
    "        sent = \" \".join(sent)\n",
    "        sent = re.sub(r'#(\\w+)', r'itstopiczzz\\1', sent)\n",
    "        sent = re.sub(r'@(\\w+)', r'itsmentionzzz\\1', sent)\n",
    "        doc = nlp(sent)\n",
    "        \n",
    "        _d = [token.lemma_ for token in doc if token.pos_ in allowed_postags and token.lemma_ not in stop_words and token.lemma_]\n",
    "#         _d = [(token.pos_, token.lemma_) for token in doc if token.lemma_ not in stop_words]\n",
    "        \n",
    "        _d = [x.replace('itstopiczzz', '#') for x in _d]\n",
    "        _d = [x.replace('itsmentionzzz', '@') for x in _d]\n",
    "        texts_out.append(_d)\n",
    "\n",
    "    return texts_out\n",
    "\n",
    "texts_out = lemmatization(texts_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(texts_out)\n",
    "\n",
    "# Create Corpus\n",
    "texts = texts_out\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train new\n",
    "from gensim.models import CoherenceModel, LdaModel\n",
    "\n",
    "lda_model = LdaModel.load(\"data/LDA-5.mod\")\n",
    "# lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=7, chunksize=1000, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.079*\"lopez-gatell\" + 0.028*\"pandemia\" + 0.024*\"cubrebocas\" + 0.023*\"dr\" + 0.017*\"salud\" + 0.015*\"@sinlineamx\" + 0.015*\"vacuna\" + 0.013*\"carta\" + 0.012*\"obrador\" + 0.012*\"@lillytellez\"'),\n",
       " (1,\n",
       "  '0.043*\"hugo\" + 0.018*\"te\" + 0.012*\"tu\" + 0.012*\"mexicanos\" + 0.010*\"cul\" + 0.010*\"@brozoxmiswebs\" + 0.010*\"peda\" + 0.010*\"envie\" + 0.008*\"@nachorgz\" + 0.007*\"cientifico\"'),\n",
       " (2,\n",
       "  '0.172*\"lopez\" + 0.081*\"mexico\" + 0.048*\"gobernadores\" + 0.037*\"covid\" + 0.033*\"19\" + 0.026*\"@rochaperiodista\" + 0.021*\"COVID\" + 0.019*\"fernandez\" + 0.013*\"personas\" + 0.011*\"hora\"'),\n",
       " (3,\n",
       "  '0.038*\"presidente\" + 0.019*\"dias\" + 0.016*\"comercial\" + 0.016*\"casa\" + 0.016*\"@lopezobrador_\" + 0.015*\"q\" + 0.013*\"peores\" + 0.013*\"marzo\" + 0.011*\"estrategia\" + 0.011*\"|\"'),\n",
       " (4,\n",
       "  '0.191*\"gatell\" + 0.025*\"renuncia\" + 0.023*\"mil\" + 0.022*\"muertos\" + 0.021*\"culpa\" + 0.020*\"A\" + 0.019*\"Y\" + 0.015*\"muertes\" + 0.014*\"DE\" + 0.013*\"piden\"'),\n",
       " (5,\n",
       "  '0.030*\"fiesta\" + 0.028*\"super\" + 0.024*\"frente\" + 0.020*\"p\" + 0.020*\"ah\" + 0.020*\"mujeres\" + 0.015*\"chatarra\" + 0.013*\"casas\" + 0.013*\"punto\" + 0.013*\"medidas\"'),\n",
       " (6,\n",
       "  '0.041*\"d\" + 0.038*\"4T\" + 0.026*\"calderon\" + 0.021*\"@mariettoponce\" + 0.021*\"jalisco\" + 0.020*\"fox\" + 0.017*\"oposicion\" + 0.015*\"siguen\" + 0.013*\"carcel\" + 0.012*\"andrade\"')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity:  -18.37148673763343\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('Perplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis, 'data/lda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in tqdm(range(start, limit, step)):\n",
    "        # model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_model = model_list[3]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_rst = {}\n",
    "\n",
    "for line in open(\"data/lda_rst.txt\"):\n",
    "    '''\n",
    "    Num Topics = 20  has Coherence Value of 0.3005\n",
    "    '''\n",
    "    if not line.startswith(\"Num\"):\n",
    "        continue\n",
    "    w = line.strip().split()\n",
    "    N = int(w[3]); score = float(w[-1])\n",
    "    if N not in lda_rst:\n",
    "        lda_rst[N] = []\n",
    "    lda_rst[N].append(score)\n",
    "# print(lda_rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lda_rst = []\n",
    "for N, scores in lda_rst.items():\n",
    "    for s in scores:\n",
    "        new_lda_rst.append({\"N\": N, \"Coherence\": s})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lda_rst = pd.DataFrame(new_lda_rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "sns.lineplot(x=\"N\", y=\"Coherence\", data=new_lda_rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After choosing the best model\n",
    "\n",
    "lda_cohen = []\n",
    "\n",
    "for line in open(\"lda_loglog.txt\"):\n",
    "    if line.startswith(\"Coherence Score: \"):\n",
    "        lda_cohen.append(float(line.strip().split()[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(lda_cohen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel, LdaModel\n",
    "\n",
    "lda_model = LdaModel.load(\"model/lda-ira-78.mod\") # best model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
